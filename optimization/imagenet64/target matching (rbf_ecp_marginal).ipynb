{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 19 20:32:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.04             Driver Version: 570.124.04     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off |   00000000:02:00.0 Off |                  Off |\n",
      "| 30%   32C    P8             11W /  450W |      87MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1522      G   /usr/lib/xorg/Xorg                       54MiB |\n",
      "|    0   N/A  N/A            1788      G   /usr/bin/gnome-shell                     12MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from \"sample pair.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_samples\n"
     ]
    }
   ],
   "source": [
    "!ls samples/64x64_diffusion/dpmsolver++_order3_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 64, 64]) torch.Size([128, 3, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3943316/3617523202.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  noises = torch.tensor(noises)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "N = 128\n",
    "M = 16\n",
    "K = 20\n",
    "root_dir = 'samples/64x64_diffusion/dpmsolver++_order3_200/image_samples/images'\n",
    "npz_file = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if '.npz' in f]\n",
    "\n",
    "noises = []\n",
    "images = []\n",
    "for file in npz_file:\n",
    "    data = np.load(file)\n",
    "    noise = data['noise']\n",
    "    image = data['image']\n",
    "    noises.append(noise)\n",
    "    images.append(image)\n",
    "\n",
    "noises = torch.tensor(noises)\n",
    "images = torch.tensor(images)\n",
    "print(noises.shape, images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 20:32:27.751898: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-19 20:32:27.771995: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-19 20:32:27.772024: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-19 20:32:27.772785: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-19 20:32:27.776805: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-19 20:32:28.276240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import random\n",
    "\n",
    "from main import parse_args_and_config, Diffusion\n",
    "from datasets import inverse_data_transform\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/data/guided-diffusion/scale/rbf_ecp_marginal_64’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /data/guided-diffusion/scale/rbf_ecp_marginal_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-19 20:32:37,643 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prepare_model] Model is ready.\n"
     ]
    }
   ],
   "source": [
    "#for NFE in [6, 8, 10, 12, 15, 20, 25]:\n",
    "for NFE in [30, 35, 40]:\n",
    "    for order in [3, 4]:\n",
    "        ###############################################################################\n",
    "        # 1) Notebook에서 sys.argv를 직접 설정 (argparse 흉내)\n",
    "        ###############################################################################\n",
    "        sys.argv = [\n",
    "            \"main.py\",\n",
    "            \"--config\", \"imagenet64.yml\",  # 사용하려는 config\n",
    "            \"--sample\",\n",
    "            \"--fid\",\n",
    "            \"--dpm_solver_type\", \"data_prediction\",\n",
    "            \"--dpm_solver_order\", f\"{order}\",\n",
    "            \"--skip_type\", \"logSNR\",\n",
    "            \"--ni\",\n",
    "\n",
    "            \"--sample_type\", \"rbf_ecp_marginal\",\n",
    "            \"--timesteps\", f\"{NFE}\",\n",
    "            \"--scale_dir\", \"/data/guided-diffusion/scale/rbf_ecp_marginal_64\",\n",
    "        ]\n",
    "\n",
    "        ###############################################################################\n",
    "        # 2) 인자/설정 로드\n",
    "        ###############################################################################\n",
    "        args, config = parse_args_and_config()\n",
    "\n",
    "        ###############################################################################\n",
    "        # 3) Diffusion 객체 생성 -> 모델 로딩\n",
    "        ###############################################################################\n",
    "        diffusion = Diffusion(args, config, rank=0)\n",
    "        diffusion.prepare_model()\n",
    "        diffusion.model.eval()\n",
    "\n",
    "        ###############################################################################\n",
    "        # 4) 배치(25장) 한 번에 샘플링 -> 5x5 그리드(여백 없이) 시각화\n",
    "        ###############################################################################\n",
    "        device = diffusion.device\n",
    "\n",
    "        for k in range(K):\n",
    "            index = np.random.randint(0, len(noises), size=(M,))\n",
    "            noise_batch = noises[index].to(device)\n",
    "            target_batch = images[index].to(device)\n",
    "            pred, _ = diffusion.sample_image(noise_batch, diffusion.model, target=target_batch, number=k)\n",
    "            loss = F.mse_loss(pred, target_batch)\n",
    "            print('NFE :', NFE, 'order :', order, 'loss :', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
