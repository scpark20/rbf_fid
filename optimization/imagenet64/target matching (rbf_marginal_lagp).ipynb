{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 27 17:18:13 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.04             Driver Version: 570.124.04     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off |   00000000:02:00.0 Off |                  Off |\n",
      "| 30%   45C    P0            187W /  450W |    8581MiB /  24564MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1522      G   /usr/lib/xorg/Xorg                       54MiB |\n",
      "|    0   N/A  N/A            1788      G   /usr/bin/gnome-shell                     12MiB |\n",
      "|    0   N/A  N/A          434758      C   ...iniconda3/envs/rbf/bin/python       1388MiB |\n",
      "|    0   N/A  N/A          442466      C   ...iniconda3/envs/rbf/bin/python       7092MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from \"sample pair.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 64, 64]) torch.Size([128, 3, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_442551/542380132.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  noises = torch.tensor(noises)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "N = 128\n",
    "M = 128\n",
    "K = 1\n",
    "root_dir = 'samples/64x64_diffusion/dpmsolver++_order3_200/image_samples/images'\n",
    "npz_file = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if '.npz' in f]\n",
    "\n",
    "noises = []\n",
    "images = []\n",
    "for file in npz_file:\n",
    "    data = np.load(file)\n",
    "    noise = data['noise']\n",
    "    image = data['image']\n",
    "    noises.append(noise)\n",
    "    images.append(image)\n",
    "\n",
    "noises = torch.tensor(noises)\n",
    "images = torch.tensor(images)\n",
    "print(noises.shape, images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 17:18:15.690584: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-27 17:18:15.709310: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-27 17:18:15.709335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-27 17:18:15.710076: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-27 17:18:15.713956: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-27 17:18:16.217514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import random\n",
    "\n",
    "from main import parse_args_and_config, Diffusion\n",
    "from datasets import inverse_data_transform\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘$/data/guided-diffusion/scale/rbf_marginal_lagp_64’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "scale_dir = '/data/guided-diffusion/scale/rbf_marginal_lagp_64'\n",
    "!mkdir ${scale_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:18:17,006 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 5, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:18:24,408 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:24,408 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=5,p=3,number=0.npz  saved!\n",
      "NFE : 5 order : 3 loss : tensor(0.0364, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 6, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:18:29,446 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:29,446 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:29,446 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=6,p=3,number=0.npz  saved!\n",
      "NFE : 6 order : 3 loss : tensor(0.0267, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 8, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:18:34,216 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:34,216 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:34,216 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:34,216 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=8,p=3,number=0.npz  saved!\n",
      "NFE : 8 order : 3 loss : tensor(0.0139, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 10, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:18:40,609 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:40,609 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:40,609 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:40,609 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:40,609 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=10,p=3,number=0.npz  saved!\n",
      "NFE : 10 order : 3 loss : tensor(0.0078, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 12, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:18:48,801 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:48,801 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:48,801 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:48,801 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:48,801 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:48,801 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=12,p=3,number=0.npz  saved!\n",
      "NFE : 12 order : 3 loss : tensor(0.0052, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 15, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:18:59,666 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:59,666 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:59,666 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:59,666 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:59,666 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:59,666 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:18:59,666 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=15,p=3,number=0.npz  saved!\n",
      "NFE : 15 order : 3 loss : tensor(0.0037, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 20, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:19:14,227 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:14,227 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:14,227 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:14,227 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:14,227 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:14,227 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:14,227 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:14,227 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=20,p=3,number=0.npz  saved!\n",
      "NFE : 20 order : 3 loss : tensor(0.0017, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 25, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:32,641 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=25,p=3,number=0.npz  saved!\n",
      "NFE : 25 order : 3 loss : tensor(0.0009, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 30, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:19:54,687 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=30,p=3,number=0.npz  saved!\n",
      "NFE : 30 order : 3 loss : tensor(0.0006, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 35, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n",
      "INFO - main.py - 2025-04-27 17:20:20,349 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=35,p=3,number=0.npz  saved!\n",
      "NFE : 35 order : 3 loss : tensor(0.0007, device='cuda:0')\n",
      "[prepare_model] Model is ready.\n",
      "rbf_marginal_lagp\n",
      "marginal in  rbf_marginal_lagp\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 64, 64]), target.shape: torch.Size([128, 3, 64, 64]), steps: 40, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/guided-diffusion/scale/rbf_marginal_lagp_64/NFE=40,p=3,number=0.npz  saved!\n",
      "NFE : 40 order : 3 loss : tensor(0.0005, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "order = 3\n",
    "for NFE in [5, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40]:\n",
    "        ###############################################################################\n",
    "        # 1) Notebook에서 sys.argv를 직접 설정 (argparse 흉내)\n",
    "        ###############################################################################\n",
    "        sys.argv = [\n",
    "            \"main.py\",\n",
    "            \"--config\", \"imagenet64.yml\",  # 사용하려는 config\n",
    "            \"--sample\",\n",
    "            \"--fid\",\n",
    "            \"--dpm_solver_type\", \"data_prediction\",\n",
    "            \"--dpm_solver_order\", f\"{order}\",\n",
    "            \"--skip_type\", \"logSNR\",\n",
    "            \"--ni\",\n",
    "\n",
    "            \"--sample_type\", \"rbf_marginal_lagp\",\n",
    "            \"--timesteps\", f\"{NFE}\",\n",
    "            \"--scale_dir\", scale_dir,\n",
    "        ]\n",
    "\n",
    "        ###############################################################################\n",
    "        # 2) 인자/설정 로드\n",
    "        ###############################################################################\n",
    "        args, config = parse_args_and_config()\n",
    "\n",
    "        ###############################################################################\n",
    "        # 3) Diffusion 객체 생성 -> 모델 로딩\n",
    "        ###############################################################################\n",
    "        diffusion = Diffusion(args, config, rank=0)\n",
    "        diffusion.prepare_model()\n",
    "        diffusion.model.eval()\n",
    "\n",
    "        ###############################################################################\n",
    "        # 4) 배치(25장) 한 번에 샘플링 -> 5x5 그리드(여백 없이) 시각화\n",
    "        ###############################################################################\n",
    "        device = diffusion.device\n",
    "\n",
    "        for k in range(K):\n",
    "            index = np.random.randint(0, len(noises), size=(M,))\n",
    "            noise_batch = noises[index].to(device)\n",
    "            target_batch = images[index].to(device)\n",
    "            pred, _ = diffusion.sample_image(noise_batch, diffusion.model, target=target_batch, number=k)\n",
    "            loss = F.mse_loss(pred, target_batch)\n",
    "            print('NFE :', NFE, 'order :', order, 'loss :', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
