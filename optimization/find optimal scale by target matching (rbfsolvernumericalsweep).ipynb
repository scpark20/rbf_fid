{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from \"sample noise data pair by Euler and save pt.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3, 64, 64]) torch.Size([1024, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "save_file = 'optimization/pair/euler_120.pt'\n",
    "pairs = torch.load(save_file)\n",
    "noise = pairs[:, 0]\n",
    "target = pairs[:, 1]\n",
    "print(noise.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - main.py - 2025-03-26 13:04:22,049 - Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prepare_model] Loading ckpt from /data/checkpoints/dpm-solver/imagenet64_uncond_100M_1500K.pt ...\n",
      "[prepare_model] Checkpoint loaded.\n",
      "[prepare_model] Model is ready.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import random\n",
    "\n",
    "from main import parse_args_and_config, Diffusion\n",
    "from datasets import inverse_data_transform\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.benchmark = False\n",
    "\n",
    "###############################################################################\n",
    "# 1) Notebook에서 sys.argv를 직접 설정 (argparse 흉내)\n",
    "###############################################################################\n",
    "sys.argv = [\n",
    "    \"main.py\",\n",
    "    \"--config\", \"imagenet64.yml\",  # 사용하려는 config\n",
    "    \"--sample\",\n",
    "    \"--sample_type\", \"rbfsolvernumericalsweep\",\n",
    "    \"--dpm_solver_type\", \"data_prediction\",\n",
    "    \"--dpm_solver_order\", \"3\",\n",
    "    \"--timesteps\", \"5\",\n",
    "    \"--skip_type\", \"logSNR\",\n",
    "    \"--log_scale_min\", \"0.0\",\n",
    "    \"--log_scale_max\", \"6.0\",\n",
    "    \"--scale_dir\", \"/data/data/rbfsolvernumericalsweep_scales\",\n",
    "    \"--ni\"\n",
    "]\n",
    "\n",
    "###############################################################################\n",
    "# 2) 인자/설정 로드\n",
    "###############################################################################\n",
    "args, config = parse_args_and_config()\n",
    "\n",
    "###############################################################################\n",
    "# 3) Diffusion 객체 생성 -> 모델 로딩\n",
    "###############################################################################\n",
    "diffusion = Diffusion(args, config, rank=0)\n",
    "diffusion.prepare_model()\n",
    "diffusion.model.eval()\n",
    "\n",
    "###############################################################################\n",
    "# 4) 배치(25장) 한 번에 샘플링 -> 5x5 그리드(여백 없이) 시각화\n",
    "###############################################################################\n",
    "device = diffusion.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/data/data/rbfsolvernumericalsweep_scales’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /data/data/rbfsolvernumericalsweep_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_scale_min : 0.0 log_scale_max : 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logpx/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/dpm_solver/rbf_solver_numerical_sweep.py:123: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  val, _ = quad(integrand, float(lambda_s), float(lambda_t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.0469, device='cuda:0'), tensor(0.0426, device='cuda:0'), tensor(0.0406, device='cuda:0'), tensor(0.0366, device='cuda:0'), tensor(0.0374, device='cuda:0'), tensor(0.0290, device='cuda:0')]\n",
      "/data/data/rbfsolvernumericalsweep_scales/NFE=5,p=3.npy  saved!\n",
      "loss : tensor(0.0290, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = 256\n",
    "noise_batch = noise[:n].to(device)\n",
    "target_batch = target[:n].to(device)\n",
    "(pred, optimal_gammas), _ = diffusion.sample_image(noise_batch, diffusion.model, target=target_batch)\n",
    "loss = F.mse_loss(pred, target_batch)\n",
    "print('loss :', loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3, 64, 64]) torch.Size([1024, 3, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prepare_model] Loading ckpt from /data/checkpoints/dpm-solver/imagenet64_uncond_100M_1500K.pt ...\n",
      "[prepare_model] Checkpoint loaded.\n",
      "[prepare_model] Model is ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logpx/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/dpm_solver/rbf_solver_quad_sweep.py:118: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  val, _ = quad(integrand, float(lambda_s), float(lambda_t))\n",
      "/home/logpx/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/dpm_solver/rbf_solver_quad_sweep.py:118: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  val, _ = quad(integrand, float(lambda_s), float(lambda_t))\n",
      " 12%|█▎        | 1/8 [00:41<04:53, 41.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data/rbfsolverquadsweep/NFE=5,p=3,exp_num=0.npy  saved!\n",
      "tensor(0.0344, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:28<04:27, 44.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data/rbfsolverquadsweep/NFE=6,p=3,exp_num=0.npy  saved!\n",
      "tensor(0.0230, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [02:33<04:29, 53.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data/rbfsolverquadsweep/NFE=8,p=3,exp_num=0.npy  saved!\n",
      "tensor(0.0106, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [04:02<04:30, 67.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data/rbfsolverquadsweep/NFE=10,p=3,exp_num=0.npy  saved!\n",
      "tensor(0.0059, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [05:52<04:08, 82.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data/rbfsolverquadsweep/NFE=12,p=3,exp_num=0.npy  saved!\n",
      "tensor(0.0045, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [08:11<03:24, 102.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data/rbfsolverquadsweep/NFE=15,p=3,exp_num=0.npy  saved!\n",
      "tensor(0.0027, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [11:17<03:45, 112.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m noise_batch = noise[:n].to(device)\n\u001b[32m     48\u001b[39m target_batch = target[:n].to(device)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m (pred, _), _ = \u001b[43mdiffusion\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(F.mse_loss(pred, target_batch))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/runners/diffusion.py:942\u001b[39m, in \u001b[36mDiffusion.sample_image\u001b[39m\u001b[34m(self, x, model, last, classifier, base_samples, target, exp_num)\u001b[39m\n\u001b[32m    933\u001b[39m solver = RBFSolverQuadSweep(\n\u001b[32m    934\u001b[39m     model_fn_continuous,\n\u001b[32m    935\u001b[39m     noise_schedule,\n\u001b[32m   (...)\u001b[39m\u001b[32m    939\u001b[39m     exp_num=\u001b[38;5;28mself\u001b[39m.args.exp_num\n\u001b[32m    940\u001b[39m )\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     x = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_by_target_matching\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdenoise\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpm_solver_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskip_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_scale_min\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_scale_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_scale_max1\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_scale_max1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_scale_max2\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_scale_max2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_scale_num\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_scale_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_num\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexp_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:    \n\u001b[32m    955\u001b[39m     x = solver.sample(\n\u001b[32m    956\u001b[39m         x,\n\u001b[32m    957\u001b[39m         steps=(\u001b[38;5;28mself\u001b[39m.args.timesteps - \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.denoise \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.timesteps),\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m         log_scale=\u001b[38;5;28mself\u001b[39m.args.log_scale,\n\u001b[32m    961\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/dpm_solver/rbf_solver_quad_sweep.py:249\u001b[39m, in \u001b[36mRBFSolverQuadSweep.sample_by_target_matching\u001b[39m\u001b[34m(self, x, target, steps, skip_type, order, log_scale_min, log_scale_max1, log_scale_max2, log_scale_num, exp_num)\u001b[39m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# predictor로 구한 x_pred를 이용해서 model_fn 평가\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m hist[i+\u001b[32m1\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# ===corrector===\u001b[39;00m\n\u001b[32m    252\u001b[39m corr_losses = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/dpm_solver/rbf_solver_quad_sweep.py:70\u001b[39m, in \u001b[36mRBFSolverQuadSweep.model_fn\u001b[39m\u001b[34m(self, x, t)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03mConvert the model to the noise prediction model or the data prediction model.\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict_x0:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_prediction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.noise_prediction_fn(x, t)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/dpm_solver/rbf_solver_quad_sweep.py:58\u001b[39m, in \u001b[36mRBFSolverQuadSweep.data_prediction_fn\u001b[39m\u001b[34m(self, x, t)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03mReturn the data prediction model (with corrector).\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     57\u001b[39m noise = \u001b[38;5;28mself\u001b[39m.noise_prediction_fn(x, t)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m alpha_t, sigma_t = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnoise_schedule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmarginal_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.noise_schedule.marginal_std(t)\n\u001b[32m     59\u001b[39m x0 = (x - sigma_t * noise) / alpha_t\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.correcting_x0_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/dpm_solver/sampler.py:140\u001b[39m, in \u001b[36mNoiseScheduleVP.marginal_alpha\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmarginal_alpha\u001b[39m(\u001b[38;5;28mself\u001b[39m, t):\n\u001b[32m    137\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m    Compute alpha_t of a given continuous-time label t in [0, T].\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.exp(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmarginal_log_mean_coeff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-fid/examples/ddpm_and_guided-diffusion/dpm_solver/sampler.py:132\u001b[39m, in \u001b[36mNoiseScheduleVP.marginal_log_mean_coeff\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03mCompute log(alpha_t) of a given continuous-time label t in [0, T].\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.schedule == \u001b[33m'\u001b[39m\u001b[33mdiscrete\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m interpolate_fn(t.reshape((-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)), \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mt_array\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.log_alpha_array.to(t.device)).reshape((-\u001b[32m1\u001b[39m))\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.schedule == \u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m0.25\u001b[39m * t ** \u001b[32m2\u001b[39m * (\u001b[38;5;28mself\u001b[39m.beta_1 - \u001b[38;5;28mself\u001b[39m.beta_0) - \u001b[32m0.5\u001b[39m * t * \u001b[38;5;28mself\u001b[39m.beta_0\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from main import parse_args_and_config, Diffusion\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "save_file = 'optimization/pair/euler_NFE=120_N=2048.pt'\n",
    "pairs = torch.load(save_file)\n",
    "noise = pairs[:, 0]\n",
    "target = pairs[:, 1]\n",
    "print(noise.shape, target.shape)\n",
    "\n",
    "model = None\n",
    "for NFE in tqdm([5, 6, 8, 10, 12, 15, 20, 25]):\n",
    "    sys.argv = [\n",
    "        \"main.py\",\n",
    "        \"--config\", \"imagenet64.yml\",  # 사용하려는 config\n",
    "        \"--sample\",\n",
    "        \"--sample_type\", \"rbfsolverquadsweep\",\n",
    "        \"--dpm_solver_type\", \"data_prediction\",\n",
    "        \"--dpm_solver_order\", \"3\",\n",
    "        \"--timesteps\", str(NFE),\n",
    "        \"--skip_type\", \"logSNR\",\n",
    "        \"--log_scale_min\", \"-6.0\",\n",
    "        \"--log_scale_max1\", \"1.0\",\n",
    "        \"--log_scale_max2\", \"6.0\",\n",
    "        \"--log_scale_num\", \"100\",\n",
    "        \"--scale_dir\", \"/data/data/rbfsolverquadsweep\",\n",
    "        \"--exp_num\", \"0\",\n",
    "        \"--verbose\", \"critical\",\n",
    "        \"--ni\",\n",
    "    ]\n",
    "\n",
    "    args, config = parse_args_and_config()\n",
    "    diffusion = Diffusion(args, config, rank=0)\n",
    "\n",
    "    if model is None:\n",
    "        diffusion.prepare_model()\n",
    "        diffusion.model.eval()\n",
    "        model = diffusion.model\n",
    "    device = diffusion.device\n",
    "\n",
    "    n = 256\n",
    "    noise_batch = noise[:n].to(device)\n",
    "    target_batch = target[:n].to(device)\n",
    "    (pred, _), _ = diffusion.sample_image(noise_batch, model, target=target_batch)\n",
    "    print(F.mse_loss(pred, target_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
